{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel-of-sandwich/Data_Mining_Project/blob/main/csc_426_501_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9r8LIbnB29C"
      },
      "source": [
        "Daniel Forbes --\n",
        "Professor Ables --\n",
        "CSC-426-501 --\n",
        "12 December 2024 \\\n",
        "Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPy0tZszLXU4"
      },
      "source": [
        "# Preface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXHofQSnCoLH"
      },
      "source": [
        "**Data:** \\\n",
        "* U.S. Centers for Disease Control and Prevention (CDC) -- 2023 BRFSS Data (SAS Transport Format) https://www.cdc.gov/brfss/annual_data/annual_2023.html\n",
        "* U.S. Centers for Disease Control and Prevention (CDC) -- 2022 BRFSS Data (SAS Transport Format) https://www.cdc.gov/brfss/annual_data/annual_2022.html\n",
        "* U.S. Census Bureau -- Annual Population Estimates, Estimated Components of Resident Population Change, and Rates of the Components of Resident Population Change for the United States, States, District of Columbia, and Puerto Rico: April 1, 2020 to July 1, 2023 (NST-EST2023-ALLDATA) https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html\n",
        "* U.S. Census Bureau -- 2023 U.S. state map data (cb_2023_us_state_500k) https://www2.census.gov/geo/tiger/GENZ2023/shp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOQENI6bCd93"
      },
      "source": [
        "**Resources used:** \\\n",
        "* Python Standard Library documentation https://docs.python.org/3/library/\n",
        "* Stack Overflow -- Unzipping files in Python https://stackoverflow.com/questions/3451111/unzipping-files-in-python\n",
        "* Statalist -- Importing problem BRFSS SAS file post 2014 https://www.statalist.org/forums/forum/general-stata-discussion/general/1621644-importing-problem-brfss-sas-file-post-2014\n",
        "* Stack Overflow -- How to rename a file using Python https://stackoverflow.com/questions/2491222/how-to-rename-a-file-using-python\n",
        "* 2023 BRFSS Codebook CDC https://www.cdc.gov/brfss/annual_data/annual_2023.html\n",
        "* NST-EST2023-ALLDATA File Layout https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2020-2023/NST-EST2023-ALLDATA.pdf\n",
        "* Calculated Variables in Data Files CDC https://www.cdc.gov/brfss/annual_data/2023/pdf/2023-calculated-variables-version4-508.pdf\n",
        "* ChatGPT https://chatgpt.com/ Note: see \"**Use of generative AI (ChatGPT)**\" below\n",
        "* Stack Overflow -- Drop rows on multiple conditions in pandas dataframe https://stackoverflow.com/questions/52456874/drop-rows-on-multiple-conditions-in-pandas-dataframe\n",
        "* Stack Overflow -- How to predict new data with a trained neural network (Tensorflow 2.0, regression analysis)? https://stackoverflow.com/questions/58939031/how-to-predict-new-data-with-a-trained-neural-network-tensorflow-2-0-regressio\n",
        "* Classroom_Examples_Teacher_Edition.ipynb on Canvas\n",
        "* How to Create Data Maps of the United States With Matplotlib https://dev.to/oscarleo/how-to-create-data-maps-of-the-united-states-with-matplotlib-p9i\n",
        "* Matplotlib user guides https://matplotlib.org/stable/users/index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl0agv3-W2xh"
      },
      "source": [
        "**Use of generative AI (ChatGPT):**\n",
        "* Creation of a state FIPS code --> state name dict (state_fips_to_name) to save time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Q5fs-MHPa2"
      },
      "source": [
        "# Installs and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWeBX_uoPlKO"
      },
      "outputs": [],
      "source": [
        "# Install wget for donwloading datasets from their respective websites\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar692iVKB55F"
      },
      "outputs": [],
      "source": [
        "# Files and directories\n",
        "from os import listdir, rename, mkdir, chdir\n",
        "from os.path import exists, isdir\n",
        "from wget import download\n",
        "import zipfile\n",
        "\n",
        "# Dataset stuff\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Model stuff\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Visualization stuff\n",
        "import seaborn as sns\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from matplotlib.patches import Patch, Circle\n",
        "from matplotlib.colors import Normalize\n",
        "from matplotlib.cm import ScalarMappable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa_kSqhUFEZJ"
      },
      "source": [
        "# Download datasets, read each one into a pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilcHDxGMPFif"
      },
      "outputs": [],
      "source": [
        "# CDC 2023 BRFSS Data dataset\n",
        "\n",
        "# Check if already in /content/\n",
        "filename_in_directory = False\n",
        "dataset_xpt_path = ''\n",
        "print('XPT and csv files currently in /content/:')\n",
        "for filename in listdir('/content'):\n",
        "  if filename.endswith('.XPT') or filename.endswith('.csv'):\n",
        "    print('\\t' + filename)\n",
        "    if filename == 'LLCP2023.XPT':\n",
        "      filename_in_directory = True\n",
        "      dataset_xpt_path = '/content/' + filename\n",
        "\n",
        "# If not already downloaded, download\n",
        "if not filename_in_directory:\n",
        "  print('\\nDownloading dataset...')\n",
        "\n",
        "  # Download zipped dataset\n",
        "  dataset_zip_link = 'https://www.cdc.gov/brfss/annual_data/2023/files/LLCP2023XPT.zip'\n",
        "  dataset_zip_filename = download(dataset_zip_link)\n",
        "  dataset_zip_path = '/content/' + dataset_zip_filename\n",
        "\n",
        "  # Unzip dataset\n",
        "  dataset_xpt_filename = 'LLCP2023.XPT ' # Space at the end\n",
        "  dataset_xpt_path = '/content/' + dataset_xpt_filename\n",
        "  with zipfile.ZipFile(dataset_zip_path, mode='r') as z:\n",
        "    z.extract(dataset_xpt_filename, path='/content')\n",
        "\n",
        "  # Remove invisible non-graphic character from end of XPT file extension. This\n",
        "  #   is a common problem when working with BRFSS datasets apparently\n",
        "  rename(dataset_xpt_path, dataset_xpt_path[:-1])\n",
        "  dataset_xpt_filename = dataset_xpt_filename[:-1]\n",
        "  dataset_xpt_path = dataset_xpt_path[:-1]\n",
        "\n",
        "  print('Dataset downloaded')\n",
        "else:\n",
        "  print('\\nDataset not downloaded, already present')\n",
        "\n",
        "# Read XPT file into a pandas DataFrame. This takes 1-2 minutes\n",
        "brfss_2023_df = pd.read_sas(dataset_xpt_path)\n",
        "\n",
        "# If write_csv = True, write df to a csv file so I can read it on LibreOffice\n",
        "write_csv = False\n",
        "if write_csv:\n",
        "  dataset_csv_filename = 'LLCP2023.csv'\n",
        "  brfss_2023_df.to_csv(dataset_csv_filename, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(brfss_2023_df.shape)"
      ],
      "metadata": {
        "id": "r4BpmQMb_3kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b42RxNnP-O2q"
      },
      "outputs": [],
      "source": [
        "# CDC 2022 (not 2023) BRFSS Data dataset\n",
        "\n",
        "# Check if already in /content/\n",
        "filename_in_directory = False\n",
        "dataset_xpt_path = ''\n",
        "print('XPT and csv files currently in /content/:')\n",
        "for filename in listdir('/content'):\n",
        "  if filename.endswith('.XPT') or filename.endswith('.csv'):\n",
        "    print('\\t' + filename)\n",
        "    if filename == 'LLCP2022.XPT':\n",
        "      filename_in_directory = True\n",
        "      dataset_xpt_path = '/content/' + filename\n",
        "\n",
        "# If not already downloaded, download\n",
        "if not filename_in_directory:\n",
        "  print('\\nDownloading dataset...')\n",
        "  # Download zipped dataset\n",
        "  dataset_zip_link = 'https://www.cdc.gov/brfss/annual_data/2022/files/LLCP2022XPT.zip'\n",
        "  dataset_zip_filename = download(dataset_zip_link)\n",
        "  dataset_zip_path = '/content/' + dataset_zip_filename\n",
        "\n",
        "  # Unzip dataset\n",
        "  dataset_xpt_filename = 'LLCP2022.XPT ' # Space at the end\n",
        "  dataset_xpt_path = '/content/' + dataset_xpt_filename\n",
        "  with zipfile.ZipFile(dataset_zip_path, mode='r') as z:\n",
        "    z.extract(dataset_xpt_filename, path='/content')\n",
        "\n",
        "  # Remove invisible non-graphic character from end of XPT file extension. This\n",
        "  #   is a common problem when working with BRFSS datasets apparently\n",
        "  rename(dataset_xpt_path, dataset_xpt_path[:-1])\n",
        "  dataset_xpt_filename = dataset_xpt_filename[:-1]\n",
        "  dataset_xpt_path = dataset_xpt_path[:-1]\n",
        "\n",
        "  print('Dataset downloaded')\n",
        "else:\n",
        "  print('\\nDataset not downloaded, already present')\n",
        "\n",
        "# Read XPT file into a pandas DataFrame. This takes 1-2 minutes\n",
        "brfss_2022_df = pd.read_sas(dataset_xpt_path)\n",
        "\n",
        "# If write_csv = True, write df to a csv file so I can read it on LibreOffice\n",
        "write_csv = False\n",
        "if write_csv:\n",
        "  dataset_csv_filename = 'LLCP2022.csv'\n",
        "  brfss_2022_df.to_csv(dataset_csv_filename, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hJ654oPBIHe"
      },
      "outputs": [],
      "source": [
        "# U.S. Census Bureau 2020-est2023 United States Population dataset\n",
        "\n",
        "# Check if already in /content/\n",
        "filename_in_directory = False\n",
        "dataset_path = ''\n",
        "print('XPT and csv files currently in /content/:')\n",
        "for filename in listdir('/content'):\n",
        "  if filename.endswith('.XPT') or filename.endswith('.csv'):\n",
        "    print('\\t' + filename)\n",
        "    if filename == 'NST-EST2023-ALLDATA.csv':\n",
        "      filename_in_directory = True\n",
        "      dataset_path = '/content/' + filename\n",
        "\n",
        "# If not already downloaded, download\n",
        "if not filename_in_directory:\n",
        "  print('\\nDownloading dataset...')\n",
        "\n",
        "  # Download dataset\n",
        "  dataset_link = 'https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/state/totals/NST-EST2023-ALLDATA.csv'\n",
        "  dataset_filename = download(dataset_link)\n",
        "  dataset_path = '/content/' + dataset_filename\n",
        "\n",
        "  print('Dataset downloaded')\n",
        "else:\n",
        "  print('\\nDataset not downloaded, already present')\n",
        "\n",
        "# Read csv file into a pandas DataFrame\n",
        "census_df = pd.read_csv(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wFGio3tCgyO"
      },
      "outputs": [],
      "source": [
        "# Final print of datasets in /content/\n",
        "print('XPT and csv files currently in /content/:')\n",
        "for filename in listdir('/content'):\n",
        "  if filename.endswith('.XPT') or filename.endswith('.csv'):\n",
        "    print('\\t' + filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN8WqdErKszK"
      },
      "source": [
        "# Extract useful features from datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UziWCpY7MdDp"
      },
      "source": [
        "If sample_size = 1, takes 81 minutes\n",
        "\n",
        "Dataset feature guide:\n",
        "* _STATE -- State FIPS Code, calculated variable. Includes territories. 1 (Alabama) to 78 (Virgin Islands). Not alphabetical nor continuous (e.g. 2 is followed by 4), use a dict. Note: Kentucky and Pennsylvania did not have enough data to be included in the 2023 BRFSS dataset. American Samoa and Northern Mariana Islands did not participate.\n",
        "* STATE -- State FIPS code like _STATE. This one is from the 2023 Census dataset.\n",
        "* LSATISFY -- Satisfaction with life. 1 (Very satisfied) to 4 (Very dissatisfied). 7 (Don't know/Not sure), 9 (Refused), and BLANK (Not asked or Missing) are ignored. Some states (e.g. Florida) didn't get this question so their LSATISFY value will be NaN.\n",
        "* EDUCA -- Education Level. 1 (Never attended school or only kindergarten) to 6 (College 4 years or more (College graduate)). 9 (Refused) and BLANK (Not asked or Missing) are ignored.\n",
        "* INCOME3 -- Income Level. 1 (Less than \\$10,000) to 11 (\\$200,000 or more). 77 (Don't know/Not sure), 99 (Refused), and BLANK (Not asked or Missing) are ignored.\n",
        "* _METSTAT -- Metropolitan Status, calculated variable. 1 (Metropolitan counties) or 2 (Nonmetropolitan counties). BLANK (Not defined or Missing) is ignored.\n",
        "* POPESTIMATE2023 -- 7/1/2023 resident total population estimate.\n",
        "* NPOPCHG_2023 -- Numeric change in resident total population 7/1/2022 to 7/1/2023."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4IPeKLyLJhb"
      },
      "outputs": [],
      "source": [
        "# Dict to find the state for a given FIPS code.\n",
        "state_fips_to_name = {\n",
        "  1: \"Alabama\",\n",
        "  2: \"Alaska\",\n",
        "  4: \"Arizona\",\n",
        "  5: \"Arkansas\",\n",
        "  6: \"California\",\n",
        "  8: \"Colorado\",\n",
        "  9: \"Connecticut\",\n",
        "  10: \"Delaware\",\n",
        "  11: \"District of Columbia\",\n",
        "  12: \"Florida\",\n",
        "  13: \"Georgia\",\n",
        "  15: \"Hawaii\",\n",
        "  16: \"Idaho\",\n",
        "  17: \"Illinois\",\n",
        "  18: \"Indiana\",\n",
        "  19: \"Iowa\",\n",
        "  20: \"Kansas\",\n",
        "  21: \"Kentucky\",\n",
        "  22: \"Louisiana\",\n",
        "  23: \"Maine\",\n",
        "  24: \"Maryland\",\n",
        "  25: \"Massachusetts\",\n",
        "  26: \"Michigan\",\n",
        "  27: \"Minnesota\",\n",
        "  28: \"Mississippi\",\n",
        "  29: \"Missouri\",\n",
        "  30: \"Montana\",\n",
        "  31: \"Nebraska\",\n",
        "  32: \"Nevada\",\n",
        "  33: \"New Hampshire\",\n",
        "  34: \"New Jersey\",\n",
        "  35: \"New Mexico\",\n",
        "  36: \"New York\",\n",
        "  37: \"North Carolina\",\n",
        "  38: \"North Dakota\",\n",
        "  39: \"Ohio\",\n",
        "  40: \"Oklahoma\",\n",
        "  41: \"Oregon\",\n",
        "  42: \"Pennsylvania\",\n",
        "  44: \"Rhode Island\",\n",
        "  45: \"South Carolina\",\n",
        "  46: \"South Dakota\",\n",
        "  47: \"Tennessee\",\n",
        "  48: \"Texas\",\n",
        "  49: \"Utah\",\n",
        "  50: \"Vermont\",\n",
        "  51: \"Virginia\",\n",
        "  53: \"Washington\",\n",
        "  54: \"West Virginia\",\n",
        "  55: \"Wisconsin\",\n",
        "  56: \"Wyoming\",\n",
        "  60: \"American Samoa\",\n",
        "  66: \"Guam\",\n",
        "  69: \"Northern Mariana Islands\",\n",
        "  72: \"Puerto Rico\",\n",
        "  78: \"Virgin Islands\"\n",
        "}\n",
        "\n",
        "# Create a new DataFrame to calculate and store feature data per state. _STATE\n",
        "#   column initialized with state FIPS codes, other columns initialized to 0.\n",
        "state_df = pd.DataFrame(data=state_fips_to_name.keys(), columns=['_STATE'])\n",
        "state_df[['LSATISFY_sum', 'LSATISFY_size', 'LSATISFY_avg', 'EDUCA_sum', \\\n",
        "  'EDUCA_size', 'EDUCA_avg', 'INCOME3_sum', 'INCOME3_size', 'INCOME3_avg', \\\n",
        "  'INCOME3_prev_sum', 'INCOME3_prev_size', 'INCOME3_prev_avg', \\\n",
        "  'income_avg_growth', '_METSTAT_sum', '_METSTAT_size', '_METSTAT_avg']] = 0\n",
        "state_df[['POPESTIMATE2023', 'NPOPCHG_2023']] = np.nan\n",
        "\n",
        "# Create a smaller sample of the BFRSS 2023 and 2022 datasets, the full ones\n",
        "#   take lots of RAM and time\n",
        "sample_size = 0.02\n",
        "sample_brfss_2023_bf = pd.DataFrame()\n",
        "sample_brfss_2022_bf = pd.DataFrame()\n",
        "if sample_size > 0 and sample_size < 1:\n",
        "  # BFRSS 2023\n",
        "  sample_brfss_2023_df = train_test_split(brfss_2023_df[['_STATE', 'LSATISFY', \\\n",
        "    'EDUCA', 'INCOME3', '_METSTAT']], train_size=sample_size, random_state=42)[0]\n",
        "  # BFRSS 2022 (not 2023)\n",
        "  sample_brfss_2022_df = train_test_split(brfss_2022_df[['_STATE', 'INCOME3']], \\\n",
        "    train_size=sample_size, random_state=42)[0]\n",
        "else:\n",
        "  # BFRSS 2023\n",
        "  sample_brfss_2023_df = brfss_2023_df[['_STATE', 'LSATISFY', 'EDUCA', \\\n",
        "    'INCOME3', '_METSTAT']]\n",
        "  # BFRSS 2022 (not 2023)\n",
        "  sample_brfss_2022_df = brfss_2023_df[['_STATE', 'INCOME3']]\n",
        "\n",
        "# Iterate through the BRFSS 2023 DataFrame rows and extract desired feature\n",
        "#   data.\n",
        "for index, row in sample_brfss_2023_df.iterrows():\n",
        "  a = row['LSATISFY']\n",
        "  if a not in [7, 9] and np.isnan(a) == False:\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], 'LSATISFY_sum'] += a\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], 'LSATISFY_size'] += 1\n",
        "\n",
        "  b = row['EDUCA']\n",
        "  if b != 9 and np.isnan(b) == False:\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], 'EDUCA_sum'] += b\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], 'EDUCA_size'] += 1\n",
        "\n",
        "  c = row['INCOME3']\n",
        "  if c not in [77, 99] and np.isnan(c) == False:\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], 'INCOME3_sum'] += c\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], 'INCOME3_size'] += 1\n",
        "\n",
        "  d = row['_METSTAT']\n",
        "  if np.isnan(d) == False:\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], '_METSTAT_sum'] += d\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], '_METSTAT_size'] += 1\n",
        "\n",
        "# Free memory\n",
        "del brfss_2023_df\n",
        "\n",
        "# Iterate through the BRFSS 2022 (not 2023) DataFrame rows and extract desired\n",
        "#   feature data.\n",
        "for index, row in sample_brfss_2022_df.iterrows():\n",
        "  c = row['INCOME3']\n",
        "  if c not in [77, 99] and np.isnan(c) == False:\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], 'INCOME3_prev_sum'] += c\n",
        "    state_df.loc[state_df['_STATE'] == row['_STATE'], 'INCOME3_prev_size'] += 1\n",
        "\n",
        "# Free memory\n",
        "del brfss_2022_df\n",
        "\n",
        "# Iterate through the 2023 census DataFrame rows and extract desired feature\n",
        "#   data.\n",
        "for index, row in census_df.iterrows():\n",
        "  if row['STATE'] in state_fips_to_name:\n",
        "    e = row['POPESTIMATE2023']\n",
        "    state_df.loc[state_df['_STATE'] == row['STATE'], 'POPESTIMATE2023'] = e\n",
        "\n",
        "    f = row['NPOPCHG_2023']\n",
        "    state_df.loc[state_df['_STATE'] == row['STATE'], 'NPOPCHG_2023'] = f\n",
        "\n",
        "# Calculate averages -- LSATISFY_avg, EDUCA_avg, INCOME3_avg, INCOME3_prev_avg,\n",
        "#   _METSTAT_avg\n",
        "for index, row in state_df.iterrows():\n",
        "  num = row['LSATISFY_sum']\n",
        "  size = row['LSATISFY_size']\n",
        "  state_df.loc[state_df['_STATE'] == row['_STATE'], 'LSATISFY_avg'] = \\\n",
        "    float(num) / float(size) if size != 0 else np.nan\n",
        "\n",
        "  num = row['EDUCA_sum']\n",
        "  size = row['EDUCA_size']\n",
        "  state_df.loc[state_df['_STATE'] == row['_STATE'], 'EDUCA_avg'] = \\\n",
        "  float(num) / float(size) if size != 0 else np.nan\n",
        "\n",
        "  num = row['INCOME3_sum']\n",
        "  size = row['INCOME3_size']\n",
        "  state_df.loc[state_df['_STATE'] == row['_STATE'], 'INCOME3_avg'] = \\\n",
        "  float(num) / float(size) if size != 0 else np.nan\n",
        "\n",
        "  num = row['INCOME3_prev_sum']\n",
        "  size = row['INCOME3_prev_size']\n",
        "  state_df.loc[state_df['_STATE'] == row['_STATE'], 'INCOME3_prev_avg'] = \\\n",
        "  float(num) / float(size) if size != 0 else np.nan\n",
        "\n",
        "  num = row['_METSTAT_sum']\n",
        "  size = row['_METSTAT_size']\n",
        "  state_df.loc[state_df['_STATE'] == row['_STATE'], '_METSTAT_avg'] = \\\n",
        "  float(num) / float(size) if size != 0 else np.nan\n",
        "\n",
        "# Calculate income_avg_growth, manually set _METSTAT_avg for certain states to\n",
        "#   1 (no metropolitan areas)\n",
        "no_metro_fips = {66, 72, 78}\n",
        "for index, row in state_df.iterrows():\n",
        "  inc23 = row['INCOME3_avg']\n",
        "  inc22 = row['INCOME3_prev_avg']\n",
        "  state_df.loc[state_df['_STATE'] == row['_STATE'], 'income_avg_growth'] = \\\n",
        "  inc23 - inc22 if inc23 != 0 and inc22 != 0 else np.nan\n",
        "\n",
        "  state_df.loc[state_df['_STATE'] == row['_STATE'], '_METSTAT_avg'] = 1 if \\\n",
        "    row['_STATE'] in no_metro_fips else row['_METSTAT_avg']\n",
        "\n",
        "# If write_csv = True, write df to csv file so I can read it on LibreOffice\n",
        "write_csv = True\n",
        "if write_csv:\n",
        "  dataset_csv_filename = 'state_df.csv'\n",
        "  state_df.to_csv(dataset_csv_filename, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl1-aWqA_kJ_"
      },
      "source": [
        "# Create and use Feed-Forward Neural Network class to predict missing LSATISFY_avg values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L76YmYY-e-p"
      },
      "outputs": [],
      "source": [
        "# A feed-forward neural network. Input DataFrame and target label list. Has a\n",
        "#   method to predict target values.\n",
        "class FFNN:\n",
        "  def __init__(self, df, target_label_list):\n",
        "    # Drop rows with missing values\n",
        "    df = df.dropna(axis=0, how='any')\n",
        "\n",
        "    # Reset index after dropping rows. Doesn't actually affect anything, just\n",
        "    #   for readability.\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    # Save pre-normalized feature metrics\n",
        "    self.describe = df.describe()\n",
        "\n",
        "    # Scale non-target features to fit [0,1]\n",
        "    self.scaler_X = MinMaxScaler()\n",
        "    df_scaled = self.scaler_X.fit_transform(df.drop(target_label_list, axis=1))\n",
        "    df_X = pd.DataFrame(df_scaled, columns=df.drop(target_label_list, axis=1).columns)\n",
        "\n",
        "    # Scale target features to fit [0,1]\n",
        "    self.scaler_y = MinMaxScaler()\n",
        "    df_target_scaled = self.scaler_y.fit_transform(df[target_label_list])\n",
        "    df_y = pd.DataFrame(df_target_scaled, columns=df[target_label_list].columns)\n",
        "    df = pd.concat([df_y, df_X], axis=1)\n",
        "\n",
        "    # Split dataset into train and test sets\n",
        "    X = df.drop(target_label_list, axis=1)\n",
        "    y = df[target_label_list]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \\\n",
        "      random_state=42)\n",
        "\n",
        "    # Split train set into train and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \\\n",
        "      test_size=0.2, random_state=42)\n",
        "    print('X_train.shape = {}\\ny_train.shape = {}'.format(X_train.shape, y_train.shape))\n",
        "\n",
        "    # Model characteristics\n",
        "    total_epochs = 100\n",
        "    try: # If shape is (int,int)\n",
        "      input_shape = X_train.shape[1]\n",
        "    except IndexError: # If shape is (int,)\n",
        "      input_shape = 1\n",
        "    try: # If shape is (int,int)\n",
        "      output_shape = y_train.shape[1]\n",
        "    except IndexError: # If shape is (int,)\n",
        "      output_shape = 1\n",
        "    hidden_nodes = X_train.shape[1]\n",
        "    activation = 'relu'\n",
        "    early_stopping = EarlyStopping(monitor='mse', patience = 5, verbose = 1)\n",
        "\n",
        "    # Initialize the model and its layers\n",
        "    self.model = Sequential([\n",
        "        # Input layer\n",
        "        Input(shape=(input_shape,)),\n",
        "        # Dense layer\n",
        "        Dense(units=hidden_nodes * 2 ** 3, activation=activation),\n",
        "        # Dense layer\n",
        "        Dense(units=hidden_nodes * 2 ** 2, activation=activation),\n",
        "        # Output layer\n",
        "        Dense(units=output_shape, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    self.model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
        "\n",
        "    # Train the model\n",
        "    history = self.model.fit(X_train, y_train, validation_data=(X_val, y_val), \\\n",
        "      epochs=total_epochs, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Get predictions\n",
        "    y_predictions = self.model.predict(X_test)\n",
        "\n",
        "    # Test the model\n",
        "    loss, mse, mae = self.model.evaluate(X_test, y_test)\n",
        "    y_pred = np.argmax(y_predictions, axis=1)\n",
        "\n",
        "    # Print model statistics\n",
        "    print('\\nFeed-Forward Neural Network\\n')\n",
        "    print('Epochs: {}'.format(len(history.epoch)))\n",
        "    print(f'MeanSquarredError (Loss): {loss:.4f}')\n",
        "    print(f'MeanAbsoluteError: {mae:.4f}')\n",
        "\n",
        "  # Input df sans LSATISFY_avg feature, return predicted LSATISFY_arg feature\n",
        "  def predict(self, X):\n",
        "    # Scale input df\n",
        "    X_scaled = pd.DataFrame(self.scaler_X.transform(X), columns=X.columns)\n",
        "    # Predict target from scaled df\n",
        "    pred = self.model.predict(X_scaled, verbose=0)\n",
        "    # Inverse scale predicted target\n",
        "    pred_scaled = pd.DataFrame(self.scaler_y.inverse_transform(pred))\n",
        "\n",
        "    return pred_scaled\n",
        "\n",
        "# Create DataFrame df from state_df that excludes the features used for\n",
        "#   calculating averages, e.g. sum and size features\n",
        "df = state_df[['_STATE', 'LSATISFY_avg', 'EDUCA_avg', 'INCOME3_avg', \\\n",
        "  'income_avg_growth', '_METSTAT_avg', 'POPESTIMATE2023', 'NPOPCHG_2023']]\n",
        "\n",
        "# Drop rows with missing values, not including LSATISFY_avg\n",
        "df = df.dropna(axis=0, how='any', subset=df.drop('LSATISFY_avg', axis=1).columns)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Create model from df. The model will predict state-average reported life\n",
        "#   satisfaction (LSATISFY_avg).\n",
        "target_label_list = pd.Series(['LSATISFY_avg'])\n",
        "model = FFNN(df.drop('_STATE', axis=1), target_label_list)\n",
        "\n",
        "# Use the model to predict missing LSATISFY_avg values\n",
        "num = 0\n",
        "for index, row in df.iterrows():\n",
        "  if np.isnan(row['LSATISFY_avg']):\n",
        "    pred = model.predict(df.loc[df['_STATE'] == row['_STATE']].drop(['_STATE', \\\n",
        "      'LSATISFY_avg'], axis=1))[0][0]\n",
        "    df.loc[df['_STATE'] == row['_STATE'], 'LSATISFY_avg'] = pred\n",
        "\n",
        "# If write_csv = True, write df's to csv files so I can read them on LibreOffice\n",
        "write_csv = True\n",
        "if write_csv:\n",
        "  dataset_csv_filename = 'df.csv'\n",
        "  df.to_csv(dataset_csv_filename, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq-ganJpy1uw"
      },
      "source": [
        "# Download map data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMESFgGuy6ZZ"
      },
      "outputs": [],
      "source": [
        "# 2023 Census Map Data dataset\n",
        "\n",
        "# Check if already in /content/\n",
        "new_dir_already_exists = False\n",
        "new_dir_path = ''\n",
        "print('directories currently in /content/:')\n",
        "for dir in listdir('/content'):\n",
        "  if isdir(dir):\n",
        "    print('\\t' + dir)\n",
        "    if dir == 'cb_2023_us_state_500k':\n",
        "      new_dir_already_exists = True\n",
        "      new_dir_path = '/content/' + dir\n",
        "\n",
        "# If not already downloaded, download\n",
        "if not new_dir_already_exists:\n",
        "  print('\\nDownloading zip...')\n",
        "\n",
        "  # Create new directory\n",
        "  new_dir = 'cb_2023_us_state_500k'\n",
        "  mkdir(new_dir)\n",
        "  new_dir_path = '/content/' + new_dir\n",
        "\n",
        "  # Download zipped dataset\n",
        "  zip_link = 'https://www2.census.gov/geo/tiger/GENZ2023/shp/cb_2023_us_state_500k.zip'\n",
        "  chdir(new_dir_path)\n",
        "  zip_filename = download(zip_link)\n",
        "  chdir('..')\n",
        "  zip_path = new_dir_path + '/' + zip_filename\n",
        "\n",
        "  # Unzip dataset\n",
        "  with zipfile.ZipFile(zip_path, mode='r') as z:\n",
        "    z.extractall(path=new_dir_path)\n",
        "\n",
        "  print('Dataset downloaded')\n",
        "else:\n",
        "  print('\\nzip not downloaded, already present')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create GeoDataFrame from DataFrame for plotting"
      ],
      "metadata": {
        "id": "vSZpdukO9KrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fn to adjust df geometry\n",
        "def translate_geometries(df, x, y, scale, rotate):\n",
        "    df.loc[:, \"geometry\"] = df.geometry.translate(yoff=y, xoff=x)\n",
        "    center = df.dissolve().centroid.iloc[0]\n",
        "    df.loc[:, \"geometry\"] = df.geometry.scale(xfact=scale, yfact=scale, \\\n",
        "      origin=center)\n",
        "    df.loc[:, \"geometry\"] = df.geometry.rotate(rotate, origin=center)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Fn to move Alaska and Hawaii closer, shrink Alaska\n",
        "def adjust_maps(df):\n",
        "    df_main_land = df[~df.STATEFP.isin([\"02\", \"15\"])]\n",
        "    df_alaska = df[df.STATEFP == \"02\"]\n",
        "    df_hawaii = df[df.STATEFP == \"15\"]\n",
        "\n",
        "    df_alaska = translate_geometries(df_alaska, 1300000, -4900000, 0.5, 32)\n",
        "    df_hawaii = translate_geometries(df_hawaii, 5400000, -1500000, 1, 24)\n",
        "\n",
        "    return pd.concat([df_main_land, df_alaska, df_hawaii])\n",
        "\n",
        "# Load and prepare geo-data, excludes the unincorporated territories\n",
        "states = gpd.read_file(\"/content/cb_2023_us_state_500k/\")\n",
        "states = states[~states.STATEFP.isin([\"72\", \"69\", \"60\", \"66\", \"78\"])]\n",
        "states = states.to_crs(\"ESRI:102003\")\n",
        "states = adjust_maps(states)\n",
        "\n",
        "# Add FIPS codes to states\n",
        "state_name_to_fips = dict(zip(state_fips_to_name.values(), \\\n",
        "  state_fips_to_name.keys()))\n",
        "states['_STATE'] = states['NAME'].map(state_name_to_fips)\n",
        "\n",
        "# Add LSATISFY_avg to states\n",
        "states['LSATISFY_avg'] = df['LSATISFY_avg'].describe()['mean']\n",
        "for index, row in states.iterrows():\n",
        "  if len(df.loc[df['_STATE'] == row['_STATE'], 'LSATISFY_avg']) > 0:\n",
        "    a = df.loc[df['_STATE'] == row['_STATE'], 'LSATISFY_avg'].iloc[0]\n",
        "  else:\n",
        "    a = df['LSATISFY_avg'].describe()['mean']\n",
        "  states.loc[states['_STATE'] == row['_STATE'], 'LSATISFY_avg'] = a\n",
        "\n",
        "# Add POPESTIMATE2023 to states\n",
        "states['POPESTIMATE2023'] = 0\n",
        "for index, row in states.iterrows():\n",
        "  if len(census_df.loc[census_df['STATE'] == row['_STATE'], 'POPESTIMATE2023']) > 0:\n",
        "    a = census_df.loc[census_df['STATE'] == row['_STATE'], 'POPESTIMATE2023'].iloc[0]\n",
        "  else:\n",
        "    a = 0\n",
        "  states.loc[states['_STATE'] == row['_STATE'], 'POPESTIMATE2023'] = a"
      ],
      "metadata": {
        "id": "DvfVFHVg9D_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot reported life satisfaction map"
      ],
      "metadata": {
        "id": "1HXjmjcSoNUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Seaborn\n",
        "edge_color = \"#30011E\"\n",
        "background_color = \"#fafafa\"\n",
        "sns.set_style({\n",
        "    \"font.family\": \"serif\",\n",
        "    \"figure.facecolor\": background_color,\n",
        "    \"axes.facecolor\": background_color,\n",
        "})\n",
        "\n",
        "# Set global font style\n",
        "sns.set_context('notebook', 1.5)\n",
        "\n",
        "# Create a color palette\n",
        "palette = sns.color_palette('coolwarm', as_cmap=True)\n",
        "\n",
        "# Normalize FIPS codes for coloring\n",
        "norm = Normalize(vmin=states['LSATISFY_avg'].describe()['min'], \\\n",
        "  vmax=states['LSATISFY_avg'].describe()['max'])\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
        "states.boundary.plot(ax=ax, linewidth=1)\n",
        "states.plot(column='LSATISFY_avg', cmap=palette, legend=False, ax=ax)\n",
        "\n",
        "# Add a title\n",
        "plt.title(\"2023 U.S. State Self-Reported Life Satisfaction\")\n",
        "\n",
        "# Add a colorbar\n",
        "sm = ScalarMappable(cmap=palette, norm=norm)\n",
        "sm._A = []  # Necessary for creating a colorbar\n",
        "cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', pad=0.05)\n",
        "cbar.set_label('State average of BRFSS LSATISFY,\\nlower (blue) is more satisfied')\n",
        "\n",
        "# Draw the plot\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fjJiNZ5_noyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot population map"
      ],
      "metadata": {
        "id": "QRpFPf6soZs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Seaborn\n",
        "edge_color = \"#30011E\"\n",
        "background_color = \"#fafafa\"\n",
        "sns.set_style({\n",
        "    \"font.family\": \"serif\",\n",
        "    \"figure.facecolor\": background_color,\n",
        "    \"axes.facecolor\": background_color,\n",
        "})\n",
        "\n",
        "# Set global font style\n",
        "sns.set_context('notebook', 1.5)\n",
        "\n",
        "# Create a color palette\n",
        "#palette = sns.color_palette('flare', as_cmap=True)\n",
        "palette = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "\n",
        "# Normalize FIPS codes for coloring\n",
        "norm = Normalize(vmin=states['POPESTIMATE2023'].describe()['min'], \\\n",
        "  vmax=states['POPESTIMATE2023'].describe()['max'])\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
        "states.boundary.plot(ax=ax, linewidth=1)\n",
        "states.plot(column='POPESTIMATE2023', cmap=palette, legend=False, ax=ax)\n",
        "\n",
        "# Add a title\n",
        "plt.title(\"2023 U.S. State Population\")\n",
        "\n",
        "# Add a colorbar\n",
        "sm = ScalarMappable(cmap=palette, norm=norm)\n",
        "sm._A = []  # Necessary for creating a colorbar\n",
        "cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', pad=0.05)\n",
        "cbar.set_label('State population')\n",
        "\n",
        "# Draw the plot\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I3VWwXZIoXwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End"
      ],
      "metadata": {
        "id": "VN8JsJ-rP-KF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlFCITsMLYL0BSz7/lKZXk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}